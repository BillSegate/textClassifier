In additive number theory, the Schnirelmann density of a sequence of numbers is a way to measure how "dense" the sequence is. It is named after Russian mathematician Lev Schnirelmann, who was the first to study it.

Definition
The Schnirelmann density of a set of natural numbers A is defined as

  
    
      
        σ
        A
        =
        
          inf
          
            n
          
        
        
          
            
              A
              (
              n
              )
            
            n
          
        
        ,
      
    
    {\displaystyle \sigma A=\inf _{n}{\frac {A(n)}{n}},}
  where A(n) denotes the number of elements of A not exceeding n and inf is infimum.The Schnirelmann density is well-defined even if the limit of A(n)/n as n → ∞ fails to exist (see upper and lower asymptotic density).

Properties
By definition, 0 ≤ A(n) ≤ n and n σA ≤ A(n) for all n, and therefore 0 ≤ σA ≤ 1, and σA = 1 if and only if A = N. Furthermore,

  
    
      
        σ
        A
        =
        0
        ⇒
        ∀
        ϵ
        >
        0
         
        ∃
        n
         
        A
        (
        n
        )
        <
        ϵ
        n
        .
      
    
    {\displaystyle \sigma A=0\Rightarrow \forall \epsilon >0\ \exists n\ A(n)<\epsilon n.}

Sensitivity
The Schnirelmann density is sensitive to the first values of a set:

  
    
      
        ∀
        k
         
        k
        ∉
        A
        ⇒
        σ
        A
        ≤
        1
        −
        1
        
          /
        
        k
      
    
    {\displaystyle \forall k\ k\notin A\Rightarrow \sigma A\leq 1-1/k}
  .In particular,

  
    
      
        1
        ∉
        A
        ⇒
        σ
        A
        =
        0
      
    
    {\displaystyle 1\notin A\Rightarrow \sigma A=0}
  and

  
    
      
        2
        ∉
        A
        ⇒
        σ
        A
        ≤
        
          
            1
            2
          
        
        .
      
    
    {\displaystyle 2\notin A\Rightarrow \sigma A\leq {\frac {1}{2}}.}
  Consequently, the Schnirelmann densities of the even numbers and the odd numbers, which one might expect to agree, are 0 and 1/2 respectively. Schnirelmann and Yuri Linnik exploited this sensitivity.

Schnirelmann's theorems
If we set 
  
    
      
        
          
            
              G
            
          
          
            2
          
        
        =
        {
        
          k
          
            2
          
        
        
          }
          
            k
            =
            1
          
          
            ∞
          
        
      
    
    {\displaystyle {\mathfrak {G}}^{2}=\{k^{2}\}_{k=1}^{\infty }}
  , then Lagrange's four-square theorem can be restated as 
  
    
      
        σ
        (
        
          
            
              G
            
          
          
            2
          
        
        ⊕
        
          
            
              G
            
          
          
            2
          
        
        ⊕
        
          
            
              G
            
          
          
            2
          
        
        ⊕
        
          
            
              G
            
          
          
            2
          
        
        )
        =
        1
      
    
    {\displaystyle \sigma ({\mathfrak {G}}^{2}\oplus {\mathfrak {G}}^{2}\oplus {\mathfrak {G}}^{2}\oplus {\mathfrak {G}}^{2})=1}
  . (Here the symbol 
  
    
      
        A
        ⊕
        B
      
    
    {\displaystyle A\oplus B}
   denotes the sumset of 
  
    
      
        A
        ∪
        {
        0
        }
      
    
    {\displaystyle A\cup \{0\}}
   and 
  
    
      
        B
        ∪
        {
        0
        }
      
    
    {\displaystyle B\cup \{0\}}
  .) It is clear that 
  
    
      
        σ
        
          
            
              G
            
          
          
            2
          
        
        =
        0
      
    
    {\displaystyle \sigma {\mathfrak {G}}^{2}=0}
  . In fact, we still have 
  
    
      
        σ
        (
        
          
            
              G
            
          
          
            2
          
        
        ⊕
        
          
            
              G
            
          
          
            2
          
        
        )
        =
        0
      
    
    {\displaystyle \sigma ({\mathfrak {G}}^{2}\oplus {\mathfrak {G}}^{2})=0}
  , and one might ask at what point the sumset attains Schnirelmann density 1 and how does it increase. It actually is the case that 
  
    
      
        σ
        (
        
          
            
              G
            
          
          
            2
          
        
        ⊕
        
          
            
              G
            
          
          
            2
          
        
        ⊕
        
          
            
              G
            
          
          
            2
          
        
        )
        =
        5
        
          /
        
        6
      
    
    {\displaystyle \sigma ({\mathfrak {G}}^{2}\oplus {\mathfrak {G}}^{2}\oplus {\mathfrak {G}}^{2})=5/6}
   and one sees that sumsetting 
  
    
      
        
          
            
              G
            
          
          
            2
          
        
      
    
    {\displaystyle {\mathfrak {G}}^{2}}
   once again yields a more populous set, namely all of 
  
    
      
        
          N
        
      
    
    {\displaystyle \mathbb {N} }
  . Schnirelmann further succeeded in developing these ideas into the following theorems, aiming towards Additive Number Theory, and proving them to be a novel resource (if not greatly powerful) to attack important problems, such as Waring's problem and Goldbach's conjecture.

Theorem. Let 
  
    
      
        A
      
    
    {\displaystyle A}
   and 
  
    
      
        B
      
    
    {\displaystyle B}
   be subsets of 
  
    
      
        
          N
        
      
    
    {\displaystyle \mathbb {N} }
  . Then

Note that 
  
    
      
        σ
        A
        +
        σ
        B
        −
        σ
        A
        ⋅
        σ
        B
        =
        1
        −
        (
        1
        −
        σ
        A
        )
        (
        1
        −
        σ
        B
        )
      
    
    {\displaystyle \sigma A+\sigma B-\sigma A\cdot \sigma B=1-(1-\sigma A)(1-\sigma B)}
  . Inductively, we have the following generalization.

Corollary. Let 
  
    
      
        
          A
          
            i
          
        
        ⊆
        
          N
        
      
    
    {\displaystyle A_{i}\subseteq \mathbb {N} }
   be a finite family of subsets of 
  
    
      
        
          N
        
      
    
    {\displaystyle \mathbb {N} }
  . Then

The theorem provides the first insights on how sumsets accumulate. It seems unfortunate that its conclusion stops short of showing 
  
    
      
        σ
      
    
    {\displaystyle \sigma }
   being superadditive. Yet, Schnirelmann provided us with the following results, which sufficed for most of his purpose.

Theorem. Let 
  
    
      
        A
      
    
    {\displaystyle A}
   and 
  
    
      
        B
      
    
    {\displaystyle B}
   be subsets of 
  
    
      
        
          N
        
      
    
    {\displaystyle \mathbb {N} }
  . If 
  
    
      
        σ
        A
        +
        σ
        B
        ≥
        1
      
    
    {\displaystyle \sigma A+\sigma B\geq 1}
  , then

Theorem. (Schnirelmann) Let 
  
    
      
        A
        ⊆
        
          N
        
      
    
    {\displaystyle A\subseteq \mathbb {N} }
  . If 
  
    
      
        σ
        A
        >
        0
      
    
    {\displaystyle \sigma A>0}
   then there exists 
  
    
      
        k
      
    
    {\displaystyle k}
   such that

Additive bases
A subset 
  
    
      
        A
        ⊆
        
          N
        
      
    
    {\displaystyle A\subseteq \mathbb {N} }
   with the property that 
  
    
      
        A
        ⊕
        A
        ⊕
        ⋯
        ⊕
        A
        =
        
          N
        
      
    
    {\displaystyle A\oplus A\oplus \cdots \oplus A=\mathbb {N} }
   for a finite sum, is called an additive basis, and the least number of summands required is called the degree (sometimes order) of the basis. Thus, the last theorem states that any set with positive Schnirelmann density is an additive basis. In this terminology, the set of squares 
  
    
      
        
          
            
              G
            
          
          
            2
          
        
        =
        {
        
          k
          
            2
          
        
        
          }
          
            k
            =
            1
          
          
            ∞
          
        
      
    
    {\displaystyle {\mathfrak {G}}^{2}=\{k^{2}\}_{k=1}^{\infty }}
   is an additive basis of degree 4. (About an open problem for additive bases, see Erdős–Turán conjecture on additive bases.)

Mann's theorem
Historically the theorems above were pointers to the following result, at one time known as the 
  
    
      
        α
        +
        β
      
    
    {\displaystyle \alpha +\beta }
   hypothesis. It was used by Edmund Landau and was finally proved by Henry Mann in 1942.

Theorem. (Mann 1942) Let 
  
    
      
        A
      
    
    {\displaystyle A}
   and 
  
    
      
        B
      
    
    {\displaystyle B}
   be subsets of 
  
    
      
        
          N
        
      
    
    {\displaystyle \mathbb {N} }
  . In case that 
  
    
      
        A
        ⊕
        B
        ≠
        
          N
        
      
    
    {\displaystyle A\oplus B\neq \mathbb {N} }
  , we still have

An analogue of this theorem for lower asymptotic density was obtained by Kneser. At a later date, E. Artin and P. Scherk simplified the proof of Mann's theorem.

Waring's problem
Let 
  
    
      
        k
      
    
    {\displaystyle k}
   and 
  
    
      
        N
      
    
    {\displaystyle N}
   be natural numbers. Let 
  
    
      
        
          
            
              G
            
          
          
            k
          
        
        =
        {
        
          i
          
            k
          
        
        
          }
          
            i
            =
            1
          
          
            ∞
          
        
      
    
    {\displaystyle {\mathfrak {G}}^{k}=\{i^{k}\}_{i=1}^{\infty }}
  . Define 
  
    
      
        
          r
          
            N
          
          
            k
          
        
        (
        n
        )
      
    
    {\displaystyle r_{N}^{k}(n)}
   to be the number of non-negative integral solutions to the equation

  
    
      
        
          x
          
            1
          
          
            k
          
        
        +
        
          x
          
            2
          
          
            k
          
        
        +
        ⋯
        +
        
          x
          
            N
          
          
            k
          
        
        =
        n
      
    
    {\displaystyle x_{1}^{k}+x_{2}^{k}+\cdots +x_{N}^{k}=n}
  and 
  
    
      
        
          R
          
            N
          
          
            k
          
        
        (
        n
        )
      
    
    {\displaystyle R_{N}^{k}(n)}
   to be the number of non-negative integral solutions to the inequality

  
    
      
        0
        ≤
        
          x
          
            1
          
          
            k
          
        
        +
        
          x
          
            2
          
          
            k
          
        
        +
        ⋯
        +
        
          x
          
            N
          
          
            k
          
        
        ≤
        n
        ,
      
    
    {\displaystyle 0\leq x_{1}^{k}+x_{2}^{k}+\cdots +x_{N}^{k}\leq n,}
  in the variables 
  
    
      
        
          x
          
            i
          
        
      
    
    {\displaystyle x_{i}}
  , respectively. Thus 
  
    
      
        
          R
          
            N
          
          
            k
          
        
        (
        n
        )
        =
        
          ∑
          
            i
            =
            0
          
          
            n
          
        
        
          r
          
            N
          
          
            k
          
        
        (
        i
        )
      
    
    {\displaystyle R_{N}^{k}(n)=\sum _{i=0}^{n}r_{N}^{k}(i)}
  . We have

  
    
      
        
          r
          
            N
          
          
            k
          
        
        (
        n
        )
        >
        0
        ↔
        n
        ∈
        N
        
          
            
              G
            
          
          
            k
          
        
        ,
      
    
    {\displaystyle r_{N}^{k}(n)>0\leftrightarrow n\in N{\mathfrak {G}}^{k},}
  

  
    
      
        
          R
          
            N
          
          
            k
          
        
        (
        n
        )
        ≥
        
          
            (
            
              
                n
                N
              
            
            )
          
          
            
              N
              k
            
          
        
        .
      
    
    {\displaystyle R_{N}^{k}(n)\geq \left({\frac {n}{N}}\right)^{\frac {N}{k}}.}
  The volume of the 
  
    
      
        N
      
    
    {\displaystyle N}
  -dimensional body defined by 
  
    
      
        0
        ≤
        
          x
          
            1
          
          
            k
          
        
        +
        
          x
          
            2
          
          
            k
          
        
        +
        ⋯
        +
        
          x
          
            N
          
          
            k
          
        
        ≤
        n
      
    
    {\displaystyle 0\leq x_{1}^{k}+x_{2}^{k}+\cdots +x_{N}^{k}\leq n}
  , is bounded by the volume of the hypercube of size 
  
    
      
        
          n
          
            1
            
              /
            
            k
          
        
      
    
    {\displaystyle n^{1/k}}
  , hence 
  
    
      
        
          R
          
            N
          
          
            k
          
        
        (
        n
        )
        =
        
          ∑
          
            i
            =
            0
          
          
            n
          
        
        
          r
          
            N
          
          
            k
          
        
        (
        i
        )
        ≤
        
          n
          
            N
            
              /
            
            k
          
        
      
    
    {\displaystyle R_{N}^{k}(n)=\sum _{i=0}^{n}r_{N}^{k}(i)\leq n^{N/k}}
  . The hard part is to show that this bound still works on the average, i.e.,

Lemma. (Linnik) For all 
  
    
      
        k
        ∈
        
          N
        
      
    
    {\displaystyle k\in \mathbb {N} }
   there exists 
  
    
      
        N
        ∈
        
          N
        
      
    
    {\displaystyle N\in \mathbb {N} }
   and a constant 
  
    
      
        c
        =
        c
        (
        k
        )
      
    
    {\displaystyle c=c(k)}
  , depending only on 
  
    
      
        k
      
    
    {\displaystyle k}
  , such that for all 
  
    
      
        n
        ∈
        
          N
        
      
    
    {\displaystyle n\in \mathbb {N} }
  ,

for all 
  
    
      
        0
        ≤
        m
        ≤
        n
        .
      
    
    {\displaystyle 0\leq m\leq n.}
  

With this at hand, the following theorem can be elegantly proved.

Theorem. For all 
  
    
      
        k
      
    
    {\displaystyle k}
   there exists 
  
    
      
        N
      
    
    {\displaystyle N}
   for which 
  
    
      
        σ
        (
        N
        
          
            
              G
            
          
          
            k
          
        
        )
        >
        0
      
    
    {\displaystyle \sigma (N{\mathfrak {G}}^{k})>0}
  .

We have thus established the general solution to Waring's Problem:

Corollary. (Hilbert 1909) For all 
  
    
      
        k
      
    
    {\displaystyle k}
   there exists 
  
    
      
        N
      
    
    {\displaystyle N}
  , depending only on 
  
    
      
        k
      
    
    {\displaystyle k}
  , such that every positive integer 
  
    
      
        n
      
    
    {\displaystyle n}
   can be expressed as the sum of at most 
  
    
      
        N
      
    
    {\displaystyle N}
   many 
  
    
      
        k
      
    
    {\displaystyle k}
  -th powers.

Schnirelmann's constant
In 1930 Schnirelmann used these ideas in conjunction with the Brun sieve to prove Schnirelmann's theorem, that any natural number greater than 1 can be written as the sum of not more than C prime numbers, where C is an effectively computable constant: Schnirelmann obtained C < 800000.  Schnirelmann's constant is the lowest number C with this property.Olivier Ramaré showed in (Ramaré 1995) that Schnirelmann's constant is at most 7, improving the earlier upper bound of 19 obtained by Hans Riesel and R. C. Vaughan.
Schnirelmann's constant is at least 3; Goldbach's conjecture implies that this is the constant's actual value.In 2013, Harald Helfgott proved Goldbach's weak conjecture for all odd numbers. Therefore, Schnirelmann's constant is at most 4.

Essential components
Khintchin proved that the sequence of squares, though of zero Schnirelmann density, when added to a sequence of Schnirelmann density between 0 and 1, increases the density:

  
    
      
        σ
        (
        A
        +
        
          
            
              G
            
          
          
            2
          
        
        )
        >
        σ
        (
        A
        )
        
           for 
        
        0
        <
        σ
        (
        A
        )
        <
        1.
      
    
    {\displaystyle \sigma (A+{\mathfrak {G}}^{2})>\sigma (A){\text{ for }}0<\sigma (A)<1.}
  This was soon simplified and extended by Erdős, who showed, that if A is any sequence with Schnirelmann density α and B is an additive basis of order k then

  
    
      
        σ
        (
        A
        +
        B
        )
        ≥
        α
        +
        
          
            
              α
              (
              1
              −
              α
              )
            
            
              2
              k
            
          
        
        
        ,
      
    
    {\displaystyle \sigma (A+B)\geq \alpha +{\frac {\alpha (1-\alpha )}{2k}}\,,}
  and this was improved by Plünnecke to

  
    
      
        σ
        (
        A
        +
        B
        )
        ≥
        
          α
          
            1
            −
            
              
                1
                k
              
            
          
        
         
        .
      
    
    {\displaystyle \sigma (A+B)\geq \alpha ^{1-{\frac {1}{k}}}\ .}
  Sequences with this property, of increasing density less than one by addition, were named essential components by Khintchin.  Linnik showed that an essential component need not be an additive basis  as he constructed an essential component that has xo(1) elements less than x.  More precisely, the sequence has

  
    
      
        
          e
          
            (
            log
            ⁡
            x
            
              )
              
                c
              
            
          
        
      
    
    {\displaystyle e^{(\log x)^{c}}}
  elements less than x for some c < 1. This was improved by E. Wirsing to

  
    
      
        
          e
          
            
              
                log
                ⁡
                x
              
            
            log
            ⁡
            log
            ⁡
            x
          
        
        .
      
    
    {\displaystyle e^{{\sqrt {\log x}}\log \log x}.}
  For a while, it remained an open problem how many elements an essential component must have. Finally, Ruzsa determined that an essential component has at least (log x)c elements up to x, for some c > 1, and for every c > 1 there is an essential component which has at most (log x)c elements up to x.

References

Hilbert, David (1909). "Beweis für die Darstellbarkeit der ganzen Zahlen durch eine feste Anzahl nter Potenzen (Waringsches Problem)". Mathematische Annalen. 67 (3): 281–300. doi:10.1007/BF01450405. ISSN 0025-5831. MR 1511530. S2CID 179177986.
Schnirelmann, L.G. (1930). "On additive properties of numbers". Ann. Inst. Polytechn. Novočerkassk (in Russian). 14: 3–28. JFM 56.0892.02.
Schnirelmann, L.G. (1933). "Über additive Eigenschaften von Zahlen". Math. Ann. (in German). 107: 649–690. doi:10.1007/BF01448914. S2CID 123067485. Zbl 0006.10402.
Mann, Henry B. (1942). "A proof of the fundamental theorem on the density of sums of sets of positive integers". Annals of Mathematics. Second Series. 43 (3): 523–527. doi:10.2307/1968807. ISSN 0003-486X. JSTOR 1968807. MR 0006748. Zbl 0061.07406.
Gelfond, A.O.; Linnik, Yu. V. (1966). L.J. Mordell (ed.). Elementary Methods in Analytic Number Theory. George Allen & Unwin.
Mann, Henry B. (1976). Addition Theorems: The Addition Theorems of Group Theory and Number Theory (Corrected reprint of 1965 Wiley ed.). Huntington, New York: Robert E. Krieger Publishing Company. ISBN 978-0-88275-418-5. MR 0424744. {{cite book}}: External link in |publisher= (help)
Nathanson, Melvyn B. (1990). "Best possible results on the density of sumsets". In Berndt, Bruce C.; Diamond, Harold G.; Halberstam, Heini; et al. (eds.). Analytic number theory. Proceedings of a conference in honor of Paul T. Bateman, held on April 25-27, 1989, at the University of Illinois, Urbana, IL (USA). Progress in Mathematics. Vol. 85. Boston: Birkhäuser. pp. 395–403. ISBN 978-0-8176-3481-0. Zbl 0722.11007.
Ramaré, O. (1995). "On Šnirel'man's constant". Annali della Scuola Normale Superiore di Pisa. Classe di Scienze. Serie IV. 22 (4): 645–706. Zbl 0851.11057. Retrieved 2011-03-28.
Nathanson, Melvyn B. (1996). Additive Number Theory: the Classical Bases. Graduate Texts in Mathematics. Vol. 164. Springer-Verlag. ISBN 978-0-387-94656-6. Zbl 0859.11002.
Nathanson, Melvyn B. (2000). Elementary Methods in Number Theory. Graduate Texts in Mathematics. Vol. 195. Springer-Verlag. pp. 359–367. ISBN 978-0-387-98912-9. Zbl 0953.11002.
Khinchin, A. Ya. (1998). Three Pearls of Number Theory. Mineola, NY: Dover. ISBN 978-0-486-40026-6. Has a proof of Mann's theorem and the Schnirelmann-density proof of Waring's conjecture.
Artin, Emil; Scherk, P. (1943). "On the sums of two set of integers". Ann. of Math. 44: 138–142. {{cite journal}}: Cite journal requires |journal= (help)
Cojocaru, Alina Carmen; Murty, M. Ram (2005). An introduction to sieve methods and their applications. London Mathematical Society Student Texts. Vol. 66. Cambridge University Press. pp. 100–105. ISBN 978-0-521-61275-3.
Ruzsa, Imre Z. (2009). "Sumsets and structure". In Geroldinger, Alfred; Ruzsa, Imre Z. (eds.). Combinatorial number theory and additive group theory. Advanced Courses in Mathematics CRM Barcelona. Elsholtz, C.; Freiman, G.; Hamidoune, Y. O.; Hegyvári, N.; Károlyi, G.; Nathanson, M.; Solymosi, J.; Stanchescu, Y. With a foreword by Javier Cilleruelo, Marc Noy and Oriol Serra (Coordinators of the DocCourse). Basel: Birkhäuser. pp. 87–210. ISBN 978-3-7643-8961-1. Zbl 1221.11026.